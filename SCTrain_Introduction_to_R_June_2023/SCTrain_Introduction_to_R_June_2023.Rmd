---
title: "SCTrain Introduction to R"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    reference_location: section
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(naniar)
library(ggplot2)
library(dplyr)
library(tidyr)
data(airquality)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion = TRUE)

load("data/iris_tidy.Rdata")
```

## Introduction to R
Historically R is a statistical language based on S and was really mainly used for statistical analysis and statistical modelling.

At the moment, it has outgrown its original focus and it could be seen as a really mature scientific language able to cover wide range of different fields in scientific computing with tools making it possible to complete production solutions from data import to results presentation with web application or API at the end.
Of course some parts could be created more efficient or even easier with different programming language, but that means introducing another programming language into the solution and it depends on the project whether that is a viable and sustainable solution or not.

Some of the reasons to consider using R in the new projects are:

- Easy to learn and use, especially for people with no programming experience.
- Enormous amount of libraries from multiple fields.
- Tools for easy integration of C/C++, JavaScript, Python and other languages.
- Usually, base packages of R introduce few breaking changes.
- Readable syntax, especially when using [Tidyverse](https://tidyverse.tidyverse.org/).
- Great environment for complex and reproducible machine learning project with [Tidymodels](https://www.tidymodels.org).
- [RStudio IDE](https://posit.co/products/open-source/rstudio/).
- [Shiny](https://rstudio.github.io/shiny/) web applications.
- Possibility to create web API with [plumber](https://www.rplumber.io) library.
- Reproducible and automatic report generation with [R Markdown](https://rmarkdown.rstudio.com) documents.

RStudio is an open-source development environment for R developed by [Posit](https://posit.co).
It contains many integration for the quick, but still robust R code development.
One of the biggest differences in the workflow to classical programming is, that one can execute each line and check the current environment at any given time.
Such workflow can be used when working with [Matlab](https://www.mathworks.com/products/matlab.html).

Its main advantage is much quicker code development, however also it requires more discipline to make the working code.
Common mistake is saving and restoring the work environment between work session, what can easily lead to scripts which expect some variable, that was manually defined in previous sessions and is not defined anywhere in the script.

![Figure: RStudio environment](images/rstudio.png){.class width="100%"}

## Basic data types and structures

In R we have several basic classes of vectors:

- Logical - TRUE, FALSE
- Numeric - 123.4, 5345.4591
- Integer - 5L, 532L, 0L
- Complex - 5 + 3i
- Character - "OK", 'test'
- Raw - binary format, `charToRaw("Test")`

To create a vector in R a function `c()` is used.
Assigning an expression to a variable is done using `<-` instead of `=` as is used in most of the programming languages.
It pretty much concatenate multiple values into one vector.

Let's take a look at some of these:
```{r data_types, exercise = TRUE}
index <- c(TRUE, FALSE, TRUE)

class(index)
```

Upon these most of the other data structures in R are built.

Another set of basic data structures in R are:

#### Lists
List are object which may contain different data types as each element of the list.
Elements of list could be vectors, functions, another lists, or pretty much any other object.
It is the most flexible data structure in R.

#### Matrices
The matrix is a data structure  which contains one data type and has two dimension.

#### Arrays
Array is similar to matrix, but instead of being two-dimensional, it is n-dimensional object.

#### Factors
Factors are defining qualitative variables with limited set of values.
Unique values of factors are also called levels.
This special data structure is mostly used for statistical analysis and is sometimes helpful also for the visualization.

#### Data Frames
Data frame is the most used structure for data analysis in R.
It is similar to matrix in a way, that it has two dimensions, but each column of data frame can contain a different data type.
In context of Tidyverse an extended version of data frame, called tibble, is used, which allows to have a list of lists which greatly enhance the possibilities, but also increases the abstraction needed to work with such data structures.

Now we will take a look at these objects in interactive window:

```{r data_structures, exercise = TRUE}
test <- list("a", c(1, 5, 6, 2), data.frame(day = 1:5, value = c(3,4,5,1,3)))

print(test)
```

When using R You may encounter also notion of object-oriented programming and related object types, however that is way beyond the scope of this training.
Interested people may read more about this in Hadley's [Advanced R](https://adv-r.hadley.nz) chapter [Base Types](https://adv-r.hadley.nz/base-types.html).

## Functional programming characteristics

R is a statistical programming language that falls into the category of functional programming.
As the name suggest this it is heavily centered around the function definitions and calling the function to get results.
Actually, there are ways to work in R that resembles more of a object oriented programming and it has its place, but for the sake of simplicity we will focus on the basics in this training.

Some characteristics of R are that:

- Data are immutable.
- It is easy to use and learn (for non-programmers).
- Great flexibility.
- Large user base.
- Enormous number of packages available in different fields.
- Can be slow and memory inefficient (but many function are actually written in C/C++).
- No direct memory control - garbage collector.


```{r, echo = TRUE}
x <- 2  # 2 is assigned to x
add_3 <- function(y){
  cat( "The value of x is ", x, "\n") # It will print x from global environment
  x <- 3   # The x is defined inside the function, this does not affect x in global environment
  y + x    # Local x is added to y
}
add_3(3) 

x # See that global x was not affected by the assignment inside the function.
```

```{r, echo = TRUE}
# It is possible to nest function into function
add_3(add_3(3))
```

- R will let you write incredibly complicated nested statements.
- That does not mean all of it is good.

More in-depth introduction to functional programming can be found [here](https://adv-r.hadley.nz/fp.html).

## [![tidyverse](images/tidyverse_logo.png){#id .class width="100"}](https://tidyverse.tidyverse.org/) Tidyverse

-   Family of R packages created for data science.
-   Designed to work together to make common data science operations more user friendly.
-   Packages have the same design philosophy, grammar, and data structures.
-   R for data science
-   Using pipe `|>` to make a chain of commands is a standard.

[![r4ds](images/r4ds_cover.png){.class width="100"}](https://r4ds.hadley.nz/)

## What we mean by tidy datasets

-   Consistent data structure, easy to manipulate, model and visualize.
-   Designed to minimize effort on cleaning data to get it ready for analysis.
-   Data tidying = data conversion into tidy form.
- We will use function `head()` to take a look at the first 10 observations of the dataset *iris* and *iris.tidy*, which are pre-loaded.

Let's look at the following well known iris dataset, you can start by clicking **"Run"** in the interactive window below.

```{r iris, exercise = TRUE}
head(iris)
```


It's tidy form looks like this:

```{r iris_tidy, exercise = TRUE}
head(iris.tidy)
```


## Tidy data definition

### There are three interconnected rules that define tidy dataset:

1.  Each <mark style="background-color: #92D6BD">variable</mark> is a <mark style="background-color: #92D6BD">column</mark>; each column is a variable.

![](images/table_iris_1.png){.class width="500"}

2.  Each <mark style="background-color: #F7B0B6">observation</mark> is a <mark style="background-color: #F7B0B6">row</mark>; each row is an observation.

![](images/table_iris_2.png){.class width="500"}

3.  Each <mark style="background-color: #FBF595">value</mark> is a <mark style="background-color: #FBF595">cell</mark>; each cell is a single value.

![](images/table_iris_3.png){.class width="500"}


## Why it is useful to have tidy data

There are two main reasons to invest time and energy to convert data into tidy format:

1. Tidy format is used all across the tidyverse universe. This consistency makes it easier to manage the tools that work with the data. 
After that, it is possible to spend more time on data analysis itself, than fighting with the tools.

2. Tidy format is particularly well suited for vectorised programming languages like R, where most built-in functions work with vectors of values.

## How to tidy messy datasets

From the tidy data definition, it may seem that the requirements for the given format are completely natural and that most of the data, that you will come into contact with in data analysis, will be in such format. But the reality is quite often different. In general, there may be several problems: data is often collected for some other purpose than data analysis and their structure is based on the requirement that their collection (and not analysis) should be as simple as possible or that the most people in real world are not familiar with the principle of tidy data and therefore the tidy format will not be their first choice (or second).

This means that any analysis will require at least some initial effort to transform the original "messy" data to tidy format. The most used operation here will be the [pivoting](https://tidyr.tidyverse.org/articles/pivot.html).

### Lengthening data

Lets take a look at the previously mentioned famous iris dataset:  

```{r iris3, exercise = TRUE}
head(iris)
```
Here, each observation describes a flower. The first four columns it's sepal length and width and petal length and width, the last column than it's species. The first four column names in this dataset contain two variables:  leaf type (with values sepal and petal) and leaf measure (with values length and width).

The key to transform this dataset to it's tidy form is to use [`dplyr::mutate()`](https://dplyr.tidyverse.org/reference/mutate.html) to assign a unique identifier to individual flowers, then the function [`tidyr::pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html).
[`tidyr::pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) takes *cols* argument as a definition of columns which should be grouped together.
Columns names will be then put into a column *name* and values will be put into a column called *value*
Now let's try to do this:

```{r pivotlonger, exercise = TRUE}
iris.tidy <- iris |> 
  dplyr::mutate(id = 1:nrow(iris))

head(iris.tidy)
```

```{r pivotlonger-solution}
iris.tidy <- iris |> 
  dplyr::mutate(id = 1:nrow(iris)) |> 
  tidyr::pivot_longer(cols = 1:4)

head(iris.tidy)
```

Right now we still need to split variable type and measure into two columns. 
This information can be found in the column *name*. 
The function [`tidyr::separate()`](https://tidyr.tidyverse.org/reference/separate.html) will be used to split the variables *type* and *measure*.
The input variable is defined by the argument *col* and names of the new variable should be defined by the argument *into* as a character vector created by function `c()`.

```{r pivotlonger2, exercise = TRUE}
iris.tidy <- iris |> 
  dplyr::mutate(id = 1:nrow(iris)) |> 
  tidyr::pivot_longer(cols = 1:4) |>
  
head(iris.tidy)
```

```{r pivotlonger2-solution}
iris.tidy <- iris |> 
  dplyr::mutate(id = 1:nrow(iris)) |> 
  tidyr::pivot_longer(cols = 1:4) |>
  tidyr::separate(col = "name",
                  into = c("type", "measure"))
head(iris.tidy)
```

### Widening data

The second commonly used function for data tidying is [`tidyr::pivot_wider()`](https://tidyr.tidyverse.org/reference/pivot_wider.html). It is the inverse transformation to `pivot_longer()`, it "widens" the data by increasing the number of columns and decreasing the number of rows.

```{r pivotwider, exercise = TRUE}
iris.tidy |> 
tidyr::pivot_wider(names_from = c("measure"),
                   values_from = "value")

```

## Exercises

The `tidyr::relig_income` dataset contains three variables: religion, income and frequency.

```{r religincome, exercise = TRUE}
tidyr::relig_income
```

To tidy it, we need to pivot longer the non-variable columns into a two-column key-value pair.
For the *cols* argument it is necessary to use *-religion* as we want to pivot all the columns except that one.

```{r religincome2, exercise = TRUE}
relig_income |> 
```

```{r religincome2-solution}
relig_income |> 
  pivot_longer(-religion,
               names_to = "income",
               values_to = "frequency"
               )
```

The `tidyr::billboard` dataset records the billboard rank of songs in the year 2000.

```{r billboard, exercise = TRUE}
tidyr::billboard
```

It has variables for artist, track, date.entered, rank and week. The rank in each week after it enters the top 100 is recorded in 75 columns, wk1 to wk76.
To tidy this dataset, we first use `pivot_longer()` to make the dataset longer. We transform the columns from wk1 to wk76 (it is possible to use *wk1:wk76* to select multiple columns with integer increments), making a new column for their names, week, and a new value for their values, rank.
After that, it doesn't hurt to clean a little by converting the week variable to a number (using [`dplyr::mutate()`](https://dplyr.tidyverse.org/reference/mutate.html) and `as.integer()` and `gsub()` functions).
`gsub()` is a function to replace part of a string. 
It takes three inputs: the first is a string with pattern we want to replace, the second is what we want to replace it with and the third is input data.
In our case we want to find *"wk"*, replace it with *""* and input is column *week*.:

```{r billboard2, exercise = TRUE}
billboard |> 
```

```{r billboard2-hint}
billboard |> 
  pivot_longer(
    wk1:wk76, 
    names_to = "week", 
    values_to = "rank", 
    values_drop_na = TRUE
  )
```

```{r billboard2-solution}
billboard |> 
  pivot_longer(
    wk1:wk76, 
    names_to = "week", 
    values_to = "rank", 
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = as.integer(gsub("wk", "", week))
  )
```

## Basic visualisation with [ggplot2](https://ggplot2.tidyverse.org)

In R one of the most used visualization libraries is [ggplot2](https://ggplot2.tidyverse.org).
It is a very structured way of creating plots based on [The Grammar of Graphics](https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448).

The minimal input for the ggplot are:

1. Data
2. Geometry function
3. Data mappings

Additionally, it is possible to change many other settings to get quite complicated data relationships into visual presentation.
In this course we will show just some basic examples of ggplot usage, which already gives us powerful visualization tool.

We will start with the *Iris* dataset.

The plots are initialized by calling `ggplot()` and passing data as an argument.
Then ggplot uses similar system as pipes, but instead of `|>` functions are chained using `+`.
To make a simple plot we will use box plot geometry called by function `geom_boxplot()` and we need to pass the variables mapping inside so called aesthetics with function `aes()` which takes arguments depending on the geometry.
In case of box plots we can pass *x* for variable to be mapped onto the x-axis and *y* for variable mapped to the y-axis.

We start with mapping *Species* to the x-axis and *Sepal.Length* to the y-axis.

```{r ggplot-iris, exercise = TRUE}
iris |> 
  ggplot() +
  geom_boxplot(aes(x = Species,
                   y = Sepal.Length))

```

Next we will switch from box plots to scatter plots.
To make a scatter plot we need to use `geom_point()`.
Let's map Petal.Width on the x-axis and *Petal.Length* on the y-axis.
In addition, to these two we can map *Species* on to the color.
We will just add `color = Species` to the `aes()` function.

```{r ggplot-iris-scatter, exercise = TRUE}
iris |> 
  ggplot() +
  geom_point(aes(x = Petal.Width,
                 y = Petal.Length,
                 color = Species))
```

To experiment a little bit more we can also try to map shape to the *Species* and size to the *Sepal.Length*.
This shows how we can add more information into the plot with simple changes of shapes, colors, size, etc.
If we want to change any of these values to the fixed value, we can do so by adding it outside `aes()` function.
This is handy for example in case we want to make all points transparent.
Then we can set `alpha = 0.5`.
Note: This technique is mostly used in cases where there are a lot of points and we need to get an information about how many points are being close together at specific area.
If the number of points is too many, it might be better to consider two dimensional distribution plots such as `geom_density_2d()` or `geom_hex()`

```{r ggplot-iris-scatter2, exercise = TRUE}
iris |> 
  ggplot() +
  geom_point(aes(x = Petal.Width,
                 y = Petal.Length,
                 color = Species,
                 shape = Species,
                 size = Sepal.Length),
             alpha = 0.5)
```

Now let's try one more thing and that is visualizing box plots based on the type and measure.
To this end we will use *iris.tidy*, since it is more suited for this kind of operation.
Into the `geom_boxplot()` aesthetics we will put *Species* on the x-axis and *value* on the y-axis.
Also, we will add *Species* to fill, so each box plot has their own color.
At this stage we would get a plot which would mix values from all the possible types (Sepal, Petal) and measures (Length, Width).
Therefore, we will separate this plot into 4 using `facet_grid()` function.
This function takes as an input names of the columns by which we want to create new plots by rows and columns.
In our case input will be `measure~type`.
This tells ggplot to group values by measure into rows and by type into columns.
Results is that we will get box plot for Petal Length into the upper left plot, Sepal Length in the upper right plot, and so on.
We can also set argument *scales* to `"free_y"`, which will make separate y-scale ranges for each row.
Since the legend automatically created by fill aesthetics is not needed in this case we can also add function `guides()` and set argument *fill* to `"none"` to disable legend.
Function `guides()` is used to control labels and legend.

```{r ggplot-iris-tidy, exercise = TRUE}
iris.tidy |> 
  ggplot() +
  geom_boxplot(aes(x = Species,
                   y = value,
                   fill = Species)) + 
  facet_grid(measure~type,
             scales = "free_y") + 
  guides(fill = "none")
```